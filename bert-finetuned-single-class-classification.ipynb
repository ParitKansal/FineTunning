{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertConfig, AutoModelForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:45.904012Z","iopub.execute_input":"2025-02-06T11:43:45.904310Z","iopub.status.idle":"2025-02-06T11:43:54.664576Z","shell.execute_reply.started":"2025-02-06T11:43:45.904287Z","shell.execute_reply":"2025-02-06T11:43:54.663622Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.665894Z","iopub.execute_input":"2025-02-06T11:43:54.666353Z","iopub.status.idle":"2025-02-06T11:43:54.750237Z","shell.execute_reply.started":"2025-02-06T11:43:54.666330Z","shell.execute_reply":"2025-02-06T11:43:54.749321Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/chat-sentiment-dataset/chat_dataset.csv\", encoding='unicode_escape')\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.751758Z","iopub.execute_input":"2025-02-06T11:43:54.752097Z","iopub.status.idle":"2025-02-06T11:43:54.822585Z","shell.execute_reply.started":"2025-02-06T11:43:54.752068Z","shell.execute_reply":"2025-02-06T11:43:54.821930Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                              message sentiment\n0          I really enjoyed the movie  positive\n1               The food was terrible  negative\n2  I'm not sure how I feel about this   neutral\n3           The service was excellent  positive\n4              I had a bad experience  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I really enjoyed the movie</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The food was terrible</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm not sure how I feel about this</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The service was excellent</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had a bad experience</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"data['positive'] = data['sentiment'] == 'positive'\ndata['negative'] = data['sentiment'] == 'negative'\ndata['neutral'] = data['sentiment'] == 'neutral'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.823377Z","iopub.execute_input":"2025-02-06T11:43:54.823682Z","iopub.status.idle":"2025-02-06T11:43:54.829332Z","shell.execute_reply.started":"2025-02-06T11:43:54.823650Z","shell.execute_reply":"2025-02-06T11:43:54.828620Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data = data.drop('sentiment', axis=1)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.830144Z","iopub.execute_input":"2025-02-06T11:43:54.830357Z","iopub.status.idle":"2025-02-06T11:43:54.857287Z","shell.execute_reply.started":"2025-02-06T11:43:54.830339Z","shell.execute_reply":"2025-02-06T11:43:54.856490Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                              message  positive  negative  neutral\n0          I really enjoyed the movie      True     False    False\n1               The food was terrible     False      True    False\n2  I'm not sure how I feel about this     False     False     True\n3           The service was excellent      True     False    False\n4              I had a bad experience     False      True    False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>positive</th>\n      <th>negative</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I really enjoyed the movie</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The food was terrible</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm not sure how I feel about this</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The service was excellent</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had a bad experience</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"labels = ['positive', 'negative','neutral']\nid2label = {idx:label for idx, label in enumerate(labels)}\nlabel2id = {label:idx for idx, label in enumerate(labels)}\nid2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.859650Z","iopub.execute_input":"2025-02-06T11:43:54.859846Z","iopub.status.idle":"2025-02-06T11:43:54.872853Z","shell.execute_reply.started":"2025-02-06T11:43:54.859830Z","shell.execute_reply":"2025-02-06T11:43:54.872097Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{0: 'positive', 1: 'negative', 2: 'neutral'}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"MAX_LEN = 128\nTRAIN_BATCH_SIZE = 8\nTEST_BATCH_SIZE = 8\nEPOCHS = 3\nLEARNING_RATE = 1e-05\nMAX_GRAD_NORM = 10\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntokenizer.model_max_length = MAX_LEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:54.874445Z","iopub.execute_input":"2025-02-06T11:43:54.874636Z","iopub.status.idle":"2025-02-06T11:43:56.495647Z","shell.execute_reply.started":"2025-02-06T11:43:54.874619Z","shell.execute_reply":"2025-02-06T11:43:56.494782Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b407341c8443109f7dffd828dc721f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e1a242e51784348bfa2cd6f5a140380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c37e8218c3b4cee85d83dc712e1209e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adbf032a3a1a400c91742570595fbbc8"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def tokenize(sentence, tokenizer):\n    tokenized_sentence = []\n\n    sentence = sentence.strip()\n\n    for word in sentence.split():  # Fixed the syntax error here\n\n        # Tokenize the word and count the number of subwords the word is broken into\n        tokenized_word = tokenizer.tokenize(word)\n\n        # Add the tokenized word to the final tokenized word list\n        tokenized_sentence.extend(tokenized_word)\n\n    return tokenized_sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.496576Z","iopub.execute_input":"2025-02-06T11:43:56.496813Z","iopub.status.idle":"2025-02-06T11:43:56.500742Z","shell.execute_reply.started":"2025-02-06T11:43:56.496784Z","shell.execute_reply":"2025-02-06T11:43:56.499937Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, label2id):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.label2id = label2id\n        self.id2label = id2label\n        \n        \n    def __getitem__(self, index):\n        sentence = self.data['message'].iloc[index]\n        labels = [\n            int(self.data['positive'].iloc[index]),\n            int(self.data['negative'].iloc[index]),\n            int(self.data['neutral'].iloc[index])\n        ]\n\n        # Tokenize and align labels\n        tokenized_sentence = tokenize(sentence, self.tokenizer)\n\n        # Add special tokens\n        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n\n        # Truncate if exceeding max length\n        if len(tokenized_sentence) > self.max_len:\n            tokenized_sentence = tokenized_sentence[:self.max_len - 1] + [\"[SEP]\"]\n\n        while len(tokenized_sentence) < self.max_len:\n            tokenized_sentence.append(\"[PAD]\")\n\n        # Attention mask (1 for real tokens, 0 for padding)\n        attn_mask = [1 if token != \"[PAD]\" else 0 for token in tokenized_sentence]\n\n        # Convert tokens and labels to IDs\n        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(attn_mask, dtype=torch.long),\n            'labels': torch.tensor(labels, dtype=torch.long)\n        }\n\n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.501610Z","iopub.execute_input":"2025-02-06T11:43:56.501807Z","iopub.status.idle":"2025-02-06T11:43:56.516435Z","shell.execute_reply.started":"2025-02-06T11:43:56.501790Z","shell.execute_reply":"2025-02-06T11:43:56.515817Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(data, test_size=0.4, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.517205Z","iopub.execute_input":"2025-02-06T11:43:56.517447Z","iopub.status.idle":"2025-02-06T11:43:56.550848Z","shell.execute_reply.started":"2025-02-06T11:43:56.517429Z","shell.execute_reply":"2025-02-06T11:43:56.550081Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"training_set = CustomDataset(train_df, tokenizer, MAX_LEN, label2id)\ntesting_set = CustomDataset(test_df, tokenizer, MAX_LEN, label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.551636Z","iopub.execute_input":"2025-02-06T11:43:56.551822Z","iopub.status.idle":"2025-02-06T11:43:56.555212Z","shell.execute_reply.started":"2025-02-06T11:43:56.551806Z","shell.execute_reply":"2025-02-06T11:43:56.554519Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.556026Z","iopub.execute_input":"2025-02-06T11:43:56.556325Z","iopub.status.idle":"2025-02-06T11:43:56.574386Z","shell.execute_reply.started":"2025-02-06T11:43:56.556293Z","shell.execute_reply":"2025-02-06T11:43:56.573409Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                             message  positive  negative  \\\n0                This weather is crazy âï¸ð§ï¸     False     False   \n1  I'm feeling so blessed to have such amazing pe...      True     False   \n2                       The book was not interesting     False      True   \n3                      The scenery here is beautiful      True     False   \n4                         This is a terrible company     False      True   \n\n   neutral  \n0     True  \n1    False  \n2    False  \n3    False  \n4    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>positive</th>\n      <th>negative</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This weather is crazy âï¸ð§ï¸</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I'm feeling so blessed to have such amazing pe...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The book was not interesting</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The scenery here is beautiful</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is a terrible company</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"training_set[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.575215Z","iopub.execute_input":"2025-02-06T11:43:56.575493Z","iopub.status.idle":"2025-02-06T11:43:56.627287Z","shell.execute_reply.started":"2025-02-06T11:43:56.575464Z","shell.execute_reply":"2025-02-06T11:43:56.626694Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'ids': tensor([  101,  1045,  1005,  1049,  3110,  2061, 10190,  2000,  2031,  2107,\n          6429,  2111,  1999,  2026,  2166,  1098, 29648,  7737,   102,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0]),\n 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor([1, 0, 0])}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"training_loader = DataLoader(training_set, batch_size = TRAIN_BATCH_SIZE, shuffle = True, num_workers = 0)\ntesting_loader = DataLoader(testing_set, batch_size = TEST_BATCH_SIZE, shuffle = False, num_workers = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.627924Z","iopub.execute_input":"2025-02-06T11:43:56.628210Z","iopub.status.idle":"2025-02-06T11:43:56.632154Z","shell.execute_reply.started":"2025-02-06T11:43:56.628185Z","shell.execute_reply":"2025-02-06T11:43:56.631375Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for batch in training_loader:\n    print(batch['ids'].shape)\n    print(batch['labels'].shape)\n    print(batch['mask'].shape)\n    print(batch['labels'])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.632809Z","iopub.execute_input":"2025-02-06T11:43:56.633082Z","iopub.status.idle":"2025-02-06T11:43:56.680101Z","shell.execute_reply.started":"2025-02-06T11:43:56.633015Z","shell.execute_reply":"2025-02-06T11:43:56.679316Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 128])\ntorch.Size([8, 3])\ntorch.Size([8, 128])\ntensor([[1, 0, 0],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 0, 1],\n        [0, 1, 0],\n        [0, 0, 1],\n        [1, 0, 0]])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n                                                           problem_type=\"multi_label_classification\", \n                                                           num_labels=len(labels),\n                                                           id2label=id2label,\n                                                           label2id=label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:43:56.680867Z","iopub.execute_input":"2025-02-06T11:43:56.681122Z","iopub.status.idle":"2025-02-06T11:44:12.201393Z","shell.execute_reply.started":"2025-02-06T11:43:56.681100Z","shell.execute_reply":"2025-02-06T11:44:12.200635Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf0b0b33b8b452c92f87936a22da431"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"with torch.no_grad():  # Prevents computation graph buildup\n    for x in testing_loader:\n        ids = x[\"ids\"].to(device)\n        mask = x[\"mask\"].to(device)\n        labels = x[\"labels\"].to(device).float()  # Convert labels to Float type\n        model = model.to(device)\n\n        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n        print(outputs)\n        \n        del ids, mask, labels\n        torch.cuda.empty_cache()\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:12.202303Z","iopub.execute_input":"2025-02-06T11:44:12.202915Z","iopub.status.idle":"2025-02-06T11:44:13.345267Z","shell.execute_reply.started":"2025-02-06T11:44:12.202881Z","shell.execute_reply":"2025-02-06T11:44:13.344326Z"}},"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=tensor(0.6780, device='cuda:0'), logits=tensor([[-0.2510, -0.1886, -0.2394],\n        [-0.1720, -0.1742, -0.1425],\n        [-0.2324, -0.1588, -0.2045],\n        [-0.0756, -0.2277, -0.0721],\n        [ 0.0632, -0.2868, -0.0052],\n        [-0.1216, -0.1800, -0.1718],\n        [-0.2984,  0.0125, -0.1158],\n        [-0.2984,  0.0125, -0.1158]], device='cuda:0'), hidden_states=None, attentions=None)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.config.label2id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.348472Z","iopub.execute_input":"2025-02-06T11:44:13.348702Z","iopub.status.idle":"2025-02-06T11:44:13.353426Z","shell.execute_reply.started":"2025-02-06T11:44:13.348683Z","shell.execute_reply":"2025-02-06T11:44:13.352569Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'positive': 0, 'negative': 1, 'neutral': 2}"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"from transformers import AdamW\nimport torch.nn as nn\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.354779Z","iopub.execute_input":"2025-02-06T11:44:13.354996Z","iopub.status.idle":"2025-02-06T11:44:13.396952Z","shell.execute_reply.started":"2025-02-06T11:44:13.354978Z","shell.execute_reply":"2025-02-06T11:44:13.396300Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Function to calculate metrics\ndef compute_metrics(preds, labels, id2label):\n    preds = (preds >= 0.5).astype(int)  # Apply threshold\n    target_names = [id2label[i] for i in range(len(id2label))]  # Extract class names in order\n    \n    accuracy = accuracy_score(labels, preds)  # Compute accuracy\n    report = classification_report(labels, preds, target_names=target_names, zero_division=1)\n\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.397574Z","iopub.execute_input":"2025-02-06T11:44:13.397826Z","iopub.status.idle":"2025-02-06T11:44:13.402420Z","shell.execute_reply.started":"2025-02-06T11:44:13.397807Z","shell.execute_reply":"2025-02-06T11:44:13.401682Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Training loop\ndef train_model(model, train_loader):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        # Move batch to GPU if available\n        input_ids = batch[\"ids\"].to(device)\n        attention_mask = batch[\"mask\"].to(device)\n        labels = batch[\"labels\"].to(device).float()  # Labels in their original type\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss  # Model already computes the loss\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Loss = {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.403111Z","iopub.execute_input":"2025-02-06T11:44:13.403318Z","iopub.status.idle":"2025-02-06T11:44:13.417472Z","shell.execute_reply.started":"2025-02-06T11:44:13.403301Z","shell.execute_reply":"2025-02-06T11:44:13.416839Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Evaluation function\ndef evaluate_model(model, val_loader):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"ids\"].to(device)\n            attention_mask = batch[\"mask\"].to(device)\n            labels = batch[\"labels\"].to(device).float()  # Labels in their original type\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss  # Model already computes the loss\n            total_loss += loss.item()\n\n            # Convert logits to probabilities\n            logits = outputs.logits\n            preds = torch.sigmoid(logits).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            all_preds.append(preds)\n            all_labels.append(labels)\n\n    avg_loss = total_loss / len(val_loader)\n\n    # Concatenate all predictions and labels\n\n    all_preds = np.vstack(all_preds)\n    all_labels = np.vstack(all_labels)\n\n    \n    print(f\"Validation Loss = {avg_loss:.4f}\")\n    # Compute metrics\n    compute_metrics(all_preds, all_labels, model.config.id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.418229Z","iopub.execute_input":"2025-02-06T11:44:13.418471Z","iopub.status.idle":"2025-02-06T11:44:13.431578Z","shell.execute_reply.started":"2025-02-06T11:44:13.418445Z","shell.execute_reply":"2025-02-06T11:44:13.430916Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"evaluate_model(model, testing_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:13.432284Z","iopub.execute_input":"2025-02-06T11:44:13.432553Z","iopub.status.idle":"2025-02-06T11:44:15.092395Z","shell.execute_reply.started":"2025-02-06T11:44:13.432527Z","shell.execute_reply":"2025-02-06T11:44:15.091527Z"}},"outputs":[{"name":"stdout","text":"Validation Loss = 0.6763\nAccuracy: 0.0684\n              precision    recall  f1-score   support\n\n    positive       0.35      0.12      0.18        68\n    negative       0.24      0.15      0.18        60\n     neutral       0.00      0.00      0.00       106\n\n   micro avg       0.25      0.07      0.11       234\n   macro avg       0.19      0.09      0.12       234\nweighted avg       0.16      0.07      0.10       234\n samples avg       0.81      0.07      0.07       234\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"for epochs in range(0, EPOCHS):\n    train_model(model, training_loader)\n    evaluate_model(model, testing_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:15.093275Z","iopub.execute_input":"2025-02-06T11:44:15.093599Z","iopub.status.idle":"2025-02-06T11:44:43.563343Z","shell.execute_reply.started":"2025-02-06T11:44:15.093570Z","shell.execute_reply":"2025-02-06T11:44:43.562389Z"}},"outputs":[{"name":"stdout","text":"Loss = 0.6064\nValidation Loss = 0.5046\nAccuracy: 0.4658\n              precision    recall  f1-score   support\n\n    positive       0.90      0.91      0.91        68\n    negative       1.00      0.00      0.00        60\n     neutral       0.96      0.44      0.61       106\n\n   micro avg       0.92      0.47      0.62       234\n   macro avg       0.95      0.45      0.50       234\nweighted avg       0.95      0.47      0.54       234\n samples avg       0.96      0.47      0.47       234\n\nLoss = 0.3441\nValidation Loss = 0.2171\nAccuracy: 0.9060\n              precision    recall  f1-score   support\n\n    positive       0.92      0.97      0.94        68\n    negative       0.90      0.92      0.91        60\n     neutral       0.93      0.88      0.90       106\n\n   micro avg       0.92      0.91      0.92       234\n   macro avg       0.92      0.92      0.92       234\nweighted avg       0.92      0.91      0.92       234\n samples avg       0.92      0.91      0.91       234\n\nLoss = 0.1505\nValidation Loss = 0.1397\nAccuracy: 0.9402\n              precision    recall  f1-score   support\n\n    positive       0.93      0.96      0.94        68\n    negative       0.98      0.92      0.95        60\n     neutral       0.95      0.95      0.95       106\n\n   micro avg       0.95      0.94      0.95       234\n   macro avg       0.95      0.94      0.95       234\nweighted avg       0.95      0.94      0.95       234\n samples avg       0.96      0.94      0.94       234\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(tokenizer.model_max_length)\nprint(model.config.id2label)\nprint(model.config.label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:43.564263Z","iopub.execute_input":"2025-02-06T11:44:43.564590Z","iopub.status.idle":"2025-02-06T11:44:43.570395Z","shell.execute_reply.started":"2025-02-06T11:44:43.564561Z","shell.execute_reply":"2025-02-06T11:44:43.569604Z"}},"outputs":[{"name":"stdout","text":"128\n{0: 'positive', 1: 'negative', 2: 'neutral'}\n{'positive': 0, 'negative': 1, 'neutral': 2}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"sentence = \"This movie ws ok\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:43.571237Z","iopub.execute_input":"2025-02-06T11:44:43.571497Z","iopub.status.idle":"2025-02-06T11:44:45.339866Z","shell.execute_reply.started":"2025-02-06T11:44:43.571473Z","shell.execute_reply":"2025-02-06T11:44:45.338782Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:45:17.065145Z","iopub.execute_input":"2025-02-06T11:45:17.065457Z","iopub.status.idle":"2025-02-06T11:45:17.071583Z","shell.execute_reply.started":"2025-02-06T11:45:17.065431Z","shell.execute_reply":"2025-02-06T11:45:17.070787Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import torch\n\n# Tokenization\ntokenized_sentence = tokenize(sentence, tokenizer)\nprint(tokenized_sentence)\n\n# Add special tokens\ntokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n\n# Truncate if too long\nmax_len = 128  # Define max length\nif len(tokenized_sentence) > tokenizer.model_max_length:\n    tokenized_sentence = tokenized_sentence[:tokenizer.model_max_length - 1] + [\"[SEP]\"]\n\n# Pad if too short\nwhile len(tokenized_sentence) < tokenizer.model_max_length:\n    tokenized_sentence.append(\"[PAD]\")\n\nprint(tokenized_sentence)\n\n# Convert tokens to IDs\nattn_mask = [1 if token != \"[PAD]\" else 0 for token in tokenized_sentence]\nids = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n\n# Convert lists to tensors\nids = torch.tensor([ids], dtype=torch.long).to(device)\nattn_mask = torch.tensor([attn_mask], dtype=torch.long).to(device)\n\n# Model inference\nwith torch.no_grad():  # Prevents computation graph buildup\n    model = model.to(device)\n    outputs = model(input_ids=ids, attention_mask=attn_mask)\n    \n    # Extract logits & apply sigmoid\n    logits = outputs.logits\n    preds = torch.sigmoid(logits).cpu().numpy()\n    \n    # Convert to binary predictions\n    preds = (preds >= 0.5).astype(int)\n    \n    # Map predictions to labels using id2label\n    predicted_labels = [model.config.id2label[i] for i, val in enumerate(preds[0]) if val == 1]\n    \n    print(f\"Raw Predictions: {preds}\")\n    print(f\"Predicted Labels: {predicted_labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:44:45.340805Z","iopub.execute_input":"2025-02-06T11:44:45.341147Z","iopub.status.idle":"2025-02-06T11:44:45.385778Z","shell.execute_reply.started":"2025-02-06T11:44:45.341121Z","shell.execute_reply":"2025-02-06T11:44:45.384913Z"}},"outputs":[{"name":"stdout","text":"['this', 'movie', 'w', '##s', 'ok']\n['[CLS]', 'this', 'movie', 'w', '##s', 'ok', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\nRaw Predictions: [[0 0 1]]\nPredicted Labels: ['neutral']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:45:49.867755Z","iopub.execute_input":"2025-02-06T11:45:49.868110Z","iopub.status.idle":"2025-02-06T11:45:49.885732Z","shell.execute_reply.started":"2025-02-06T11:45:49.868082Z","shell.execute_reply":"2025-02-06T11:45:49.884781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c08d3ca8f24cc68477e8371effecfa"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"model_name = \"bert-finetuned-single_class_classification\"\n\n# Upload tokenizer to the hub\ntokenizer.push_to_hub(\n    repo_id=\"ParitKansal/{}\".format(model_name),  # Correct repo_id format\n    commit_message=\"Add tokenizer\",\n    use_temp_dir=True,\n)\n\n# Upload model to the hub\nmodel.push_to_hub(\n    repo_id=\"ParitKansal/{}\".format(model_name),  # Correct repo_id format\n    commit_message=\"Add model\",\n    use_temp_dir=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:45:56.323798Z","iopub.execute_input":"2025-02-06T11:45:56.324119Z","iopub.status.idle":"2025-02-06T11:46:17.926847Z","shell.execute_reply.started":"2025-02-06T11:45:56.324094Z","shell.execute_reply":"2025-02-06T11:46:17.925401Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc3d3b581844fd0bea4d653141b6a7c"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748fe5d2f1794c568a93c605c829aaae"}},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ParitKansal/bert-finetuned-single_class_classification/commit/759ba0e88869b5d082906e07aa761f8f9652d7fb', commit_message='Add model', commit_description='', oid='759ba0e88869b5d082906e07aa761f8f9652d7fb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ParitKansal/bert-finetuned-single_class_classification', endpoint='https://huggingface.co', repo_type='model', repo_id='ParitKansal/bert-finetuned-single_class_classification'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"model_ = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:46:33.074333Z","iopub.execute_input":"2025-02-06T11:46:33.074627Z","iopub.status.idle":"2025-02-06T11:46:33.078377Z","shell.execute_reply.started":"2025-02-06T11:46:33.074604Z","shell.execute_reply":"2025-02-06T11:46:33.077340Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"tokenizer_ = tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:46:45.619004Z","iopub.execute_input":"2025-02-06T11:46:45.619335Z","iopub.status.idle":"2025-02-06T11:46:45.623371Z","shell.execute_reply.started":"2025-02-06T11:46:45.619313Z","shell.execute_reply":"2025-02-06T11:46:45.622376Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load the pre-trained tokenizer and model\nmodel_name = \"ParitKansal/bert-finetuned-single_class_classification\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:46:48.839359Z","iopub.execute_input":"2025-02-06T11:46:48.839632Z","iopub.status.idle":"2025-02-06T11:47:01.686385Z","shell.execute_reply.started":"2025-02-06T11:46:48.839612Z","shell.execute_reply":"2025-02-06T11:47:01.685701Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdcd2c435404e01a328da99d4ba6979"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd77f02f666c48379d98d40cca1fd28d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c43960530ab4a40b5e22f2c64d853c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a981ccd0be144ae89dceaf4e4f87c296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370738c108ca4a76b2c8c25c5adad583"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import torch\nsentence = \"This movie ws ok\"\n# Tokenization\ntokenized_sentence = tokenize(sentence, tokenizer)\nprint(tokenized_sentence)\n\n# Add special tokens\ntokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n\n# Truncate if too long\nmax_len = 128  # Define max length\nif len(tokenized_sentence) > tokenizer.model_max_length:\n    tokenized_sentence = tokenized_sentence[:tokenizer.model_max_length - 1] + [\"[SEP]\"]\n\n# Pad if too short\nwhile len(tokenized_sentence) < tokenizer.model_max_length:\n    tokenized_sentence.append(\"[PAD]\")\n\nprint(tokenized_sentence)\n\n# Convert tokens to IDs\nattn_mask = [1 if token != \"[PAD]\" else 0 for token in tokenized_sentence]\nids = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n\n# Convert lists to tensors\nids = torch.tensor([ids], dtype=torch.long).to(device)\nattn_mask = torch.tensor([attn_mask], dtype=torch.long).to(device)\n\n# Model inference\nwith torch.no_grad():  # Prevents computation graph buildup\n    model = model.to(device)\n    outputs = model(input_ids=ids, attention_mask=attn_mask)\n    \n    # Extract logits & apply sigmoid\n    logits = outputs.logits\n    preds = torch.sigmoid(logits).cpu().numpy()\n    \n    # Convert to binary predictions\n    preds = (preds >= 0.5).astype(int)\n    \n    # Map predictions to labels using id2label\n    predicted_labels = [model.config.id2label[i] for i, val in enumerate(preds[0]) if val == 1]\n    \n    print(f\"Raw Predictions: {preds}\")\n    print(f\"Predicted Labels: {predicted_labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T11:47:15.357017Z","iopub.execute_input":"2025-02-06T11:47:15.357352Z","iopub.status.idle":"2025-02-06T11:47:15.538214Z","shell.execute_reply.started":"2025-02-06T11:47:15.357328Z","shell.execute_reply":"2025-02-06T11:47:15.537493Z"}},"outputs":[{"name":"stdout","text":"['this', 'movie', 'w', '##s', 'ok']\n['[CLS]', 'this', 'movie', 'w', '##s', 'ok', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\nRaw Predictions: [[0 0 1]]\nPredicted Labels: ['neutral']\n","output_type":"stream"}],"execution_count":37}]}